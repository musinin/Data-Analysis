{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T06:10:49.459680Z",
     "iopub.status.busy": "2025-05-01T06:10:49.459410Z",
     "iopub.status.idle": "2025-05-01T06:10:51.183361Z",
     "shell.execute_reply": "2025-05-01T06:10:51.182194Z",
     "shell.execute_reply.started": "2025-05-01T06:10:49.459650Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import googleapiclient.discovery\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T06:11:15.686713Z",
     "iopub.status.busy": "2025-05-01T06:11:15.686307Z",
     "iopub.status.idle": "2025-05-01T06:11:15.705548Z",
     "shell.execute_reply": "2025-05-01T06:11:15.704481Z",
     "shell.execute_reply.started": "2025-05-01T06:11:15.686677Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# YouTube API key\n",
    "API_KEY = \"AIzaSyC43Ohag0uBkVRGx9vX1G9mZ1evWvW8qS4\" # YOUR-API-KEY\n",
    "youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T06:13:01.269652Z",
     "iopub.status.busy": "2025-05-01T06:13:01.269187Z",
     "iopub.status.idle": "2025-05-01T06:13:01.279619Z",
     "shell.execute_reply": "2025-05-01T06:13:01.278190Z",
     "shell.execute_reply.started": "2025-05-01T06:13:01.269614Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get video ids for query. Youtube API allows only up to 50 videos\n",
    "\n",
    "def get_video_ids(query, max_results=100):\n",
    "    video_ids = []\n",
    "    results_per_page = 50  # YouTube API maxResults \n",
    "    pages = (max_results + results_per_page - 1) // results_per_page  # calculate #pages\n",
    "    next_page_token = None\n",
    "    \n",
    "    for _ in range(pages): # call api as many times as #pages\n",
    "        try:\n",
    "            request = youtube.search().list(\n",
    "                q=query,\n",
    "                part=\"snippet\",\n",
    "                maxResults=results_per_page,\n",
    "                type=\"video\",\n",
    "                pageToken=next_page_token\n",
    "            )\n",
    "            response = request.execute()      \n",
    "\n",
    "            # Only check if 'id' key exists and 'videoId' is accessible\n",
    "            for item in response['items']:\n",
    "                if isinstance(item, dict) and 'id' in item and 'videoId' in item['id']:\n",
    "                    video_ids.append(item['id']['videoId'])\n",
    "\n",
    "            next_page_token = response.get('nextPageToken')\n",
    "            if not next_page_token:\n",
    "                break\n",
    "\n",
    "        except HttpError as e:\n",
    "            error_reason = e.resp.get('reason')\n",
    "            if error_reason == 'quotaExceeded':\n",
    "                print(\"Quota exceeded. Saving collected data...\")\n",
    "                save_data_to_csv(video_comments)\n",
    "                exit()\n",
    "            else:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                \n",
    "    return video_ids[:max_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T06:15:04.833145Z",
     "iopub.status.busy": "2025-05-01T06:15:04.832712Z",
     "iopub.status.idle": "2025-05-01T06:15:04.840788Z",
     "shell.execute_reply": "2025-05-01T06:15:04.839621Z",
     "shell.execute_reply.started": "2025-05-01T06:15:04.833109Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get comments for 1 video. Youtube API allows only up to 100 comments per video\n",
    "def get_top_korean_comments(video_id, max_results=100):\n",
    "    comments = []\n",
    "    try:\n",
    "        request = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            maxResults=max_results,\n",
    "            textFormat=\"plainText\"\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "            comments.append(comment)  \n",
    "                \n",
    "    except HttpError as e:\n",
    "        error_reason = e.resp.get('reason')\n",
    "        if error_reason == 'commentsDisabled':\n",
    "            print(f\"Comments are disabled for video {video_id}. Skipping.\")\n",
    "        elif error_reason == 'quotaExceeded':\n",
    "            print(\"Quota exceeded. Saving collected data...\")\n",
    "            save_data_to_csv(video_comments)\n",
    "            exit()\n",
    "        else:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    \n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T06:15:21.008779Z",
     "iopub.status.busy": "2025-05-01T06:15:21.008001Z",
     "iopub.status.idle": "2025-05-01T06:15:21.014534Z",
     "shell.execute_reply": "2025-05-01T06:15:21.013431Z",
     "shell.execute_reply.started": "2025-05-01T06:15:21.008735Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Make data to dataframe\n",
    "# video_comments looks like: {\"4DUYBXdUYzA\": [\"와 재밌다\", \"재미없다\", ]}\n",
    "def save_data_to_csv(video_comments):    \n",
    "    \n",
    "    data = {\"Video_ID\": [], \"Comment\": []}\n",
    "    \n",
    "    for video_id, comments in video_comments.items():\n",
    "        for comment in comments:\n",
    "            data[\"Video_ID\"].append(video_id)\n",
    "            data[\"Comment\"].append(comment)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Export to CSV \n",
    "    df.to_csv(\"youtube_comments.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T06:18:14.368070Z",
     "iopub.status.busy": "2025-05-01T06:18:14.367668Z",
     "iopub.status.idle": "2025-05-01T06:18:14.374234Z",
     "shell.execute_reply": "2025-05-01T06:18:14.372984Z",
     "shell.execute_reply.started": "2025-05-01T06:18:14.368034Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "participants = [\"흑백요리사\",\"백종원\",\"안성재\",\"에드워드 리\",\"나폴리 맛피아\",\"트리플스타\",\"요리하는 돌아이\",\"최현석\",\"장호준\",\"여경래\",\"안유성\",\"정지선\",\"최강록\",\"조은주\",\"오세득\",\"파브리치오 페라리\",\"이영숙\",\"선경 롱게스트\",\"김도윤\",\"박준우\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T06:18:15.985287Z",
     "iopub.status.busy": "2025-05-01T06:18:15.984861Z",
     "iopub.status.idle": "2025-05-01T06:19:28.839882Z",
     "shell.execute_reply": "2025-05-01T06:19:28.838614Z",
     "shell.execute_reply.started": "2025-05-01T06:18:15.985245Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:15<04:49, 15.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.248111009597778s for query: 흑백요리사 흑백요리사\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:28<04:17, 14.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.887962102890015s for query: 흑백요리사 백종원\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:42<04:01, 14.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.94471049308777s for query: 흑백요리사 안성재\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:57<03:51, 14.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.860220432281494s for query: 흑백요리사 에드워드 리\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [01:14<03:46, 15.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.05014872550964s for query: 흑백요리사 나폴리 맛피아\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [01:27<03:24, 14.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.63070130348206s for query: 흑백요리사 트리플스타\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [01:41<03:04, 14.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101.0162513256073s for query: 흑백요리사 요리하는 돌아이\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [01:56<02:56, 14.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116.82235884666443s for query: 흑백요리사 최현석\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [02:12<02:44, 14.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132.1999397277832s for query: 흑백요리사 장호준\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [02:25<02:23, 14.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145.16038131713867s for query: 흑백요리사 여경래\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [02:39<02:08, 14.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159.2785131931305s for query: 흑백요리사 안유성\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [02:53<01:54, 14.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173.82319259643555s for query: 흑백요리사 정지선\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [03:09<01:42, 14.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189.16910910606384s for query: 흑백요리사 최강록\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [03:22<01:25, 14.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202.27476477622986s for query: 흑백요리사 조은주\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [03:34<01:08, 13.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214.5624566078186s for query: 흑백요리사 오세득\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [03:46<00:52, 13.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226.22314310073853s for query: 흑백요리사 파브리치오 페라리\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [03:59<00:39, 13.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239.5098898410797s for query: 흑백요리사 이영숙\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [04:12<00:25, 12.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252.01423382759094s for query: 흑백요리사 선경 롱게스트\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [04:23<00:12, 12.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263.0879054069519s for query: 흑백요리사 김도윤\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [04:34<00:00, 13.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274.48420906066895s for query: 흑백요리사 박준우\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "video_comments = {}\n",
    "# Ex: {\"4DUYBXdUYzA\": [\"와 재밌다\", \"재미없다\", ]}\n",
    "\n",
    "start = time.time()\n",
    "query_baisic = \"흑백요리사\"\n",
    "\n",
    "for participant in tqdm.tqdm(participants):\n",
    "    query = query_baisic + \" \" + participant \n",
    "\n",
    "    try:\n",
    "        video_ids = get_video_ids(query, max_results=50) \n",
    "\n",
    "        for video_id in video_ids:\n",
    "            comments = get_top_korean_comments(video_id)\n",
    "            video_comments[video_id] = comments\n",
    "    except HttpError as e:\n",
    "        if e.resp.get('reason') == 'quotaExceeded':\n",
    "            print(\"Quota exceeded. Saving collected data...\")\n",
    "            save_data_to_csv(video_comments)\n",
    "            exit()\n",
    "\n",
    "    end = time.time()    \n",
    "    print(f\"{end - start}s for query: {query}\")    \n",
    "\n",
    "save_data_to_csv(video_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge youtube_comments with movie_rating_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T06:21:21.027216Z",
     "iopub.status.busy": "2025-05-01T06:21:21.025973Z",
     "iopub.status.idle": "2025-05-01T06:21:21.167065Z",
     "shell.execute_reply": "2025-05-01T06:21:21.166164Z",
     "shell.execute_reply.started": "2025-05-01T06:21:21.027080Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "comments = pd.read_csv(\"youtube_comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T06:21:27.027194Z",
     "iopub.status.busy": "2025-05-01T06:21:27.026785Z",
     "iopub.status.idle": "2025-05-01T06:21:27.047443Z",
     "shell.execute_reply": "2025-05-01T06:21:27.046081Z",
     "shell.execute_reply.started": "2025-05-01T06:21:27.027156Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video_ID</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vebF7wUQLMo</td>\n",
       "      <td>《흑백요리사: 요리 계급 전쟁》, 9월 17일 넷플릭스에서 시청하세요: https:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vebF7wUQLMo</td>\n",
       "      <td>빽햄요리사ㄷㄷ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vebF7wUQLMo</td>\n",
       "      <td>0:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vebF7wUQLMo</td>\n",
       "      <td>백수저중에 옴진리교 교주가 있노 ㄷㄷㄷㄷ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vebF7wUQLMo</td>\n",
       "      <td>심사위원 등장씬은 대한민국 역대 등장씬 고트중에 하나다 ㄹㅇ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Video_ID                                            Comment\n",
       "0  vebF7wUQLMo  《흑백요리사: 요리 계급 전쟁》, 9월 17일 넷플릭스에서 시청하세요: https:...\n",
       "1  vebF7wUQLMo                                            빽햄요리사ㄷㄷ\n",
       "2  vebF7wUQLMo                                               0:07\n",
       "3  vebF7wUQLMo                             백수저중에 옴진리교 교주가 있노 ㄷㄷㄷㄷ\n",
       "4  vebF7wUQLMo                  심사위원 등장씬은 대한민국 역대 등장씬 고트중에 하나다 ㄹㅇ"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T06:28:13.682985Z",
     "iopub.status.busy": "2024-10-30T06:28:13.682572Z",
     "iopub.status.idle": "2024-10-30T06:28:15.360465Z",
     "shell.execute_reply": "2024-10-30T06:28:15.359218Z",
     "shell.execute_reply.started": "2024-10-30T06:28:13.682949Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "# download naver movie ratings dataset\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T06:28:36.961445Z",
     "iopub.status.busy": "2024-10-30T06:28:36.960981Z",
     "iopub.status.idle": "2024-10-30T06:28:37.755561Z",
     "shell.execute_reply": "2024-10-30T06:28:37.754322Z",
     "shell.execute_reply.started": "2024-10-30T06:28:36.961403Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "movie_data = pd.read_table('ratings.txt')\n",
    "movie_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T06:43:07.797803Z",
     "iopub.status.busy": "2024-10-30T06:43:07.797368Z",
     "iopub.status.idle": "2024-10-30T06:43:07.808645Z",
     "shell.execute_reply": "2024-10-30T06:43:07.807503Z",
     "shell.execute_reply.started": "2024-10-30T06:43:07.797764Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T06:43:02.244862Z",
     "iopub.status.busy": "2024-10-30T06:43:02.244443Z",
     "iopub.status.idle": "2024-10-30T06:43:02.250785Z",
     "shell.execute_reply": "2024-10-30T06:43:02.249519Z",
     "shell.execute_reply.started": "2024-10-30T06:43:02.244826Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"movie data length: {len(movie_data)}\")\n",
    "print(f\"comments data length: {len(comments)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T06:40:53.343765Z",
     "iopub.status.busy": "2024-10-30T06:40:53.343290Z",
     "iopub.status.idle": "2024-10-30T06:40:53.390770Z",
     "shell.execute_reply": "2024-10-30T06:40:53.389651Z",
     "shell.execute_reply.started": "2024-10-30T06:40:53.343725Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Merge two dataset because number of Comments dataset is not big enough to train word vectors.\n",
    "df1_text = movie_data[['document']].rename(columns={'document': 'text'})\n",
    "df2_text = comments[['Comment']].rename(columns={'Comment': 'text'})\n",
    "\n",
    "# merge movie_data and yt_comments_data\n",
    "merged_df = pd.concat([df1_text, df2_text], ignore_index=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T06:41:29.091547Z",
     "iopub.status.busy": "2024-10-30T06:41:29.090737Z",
     "iopub.status.idle": "2024-10-30T06:41:29.113326Z",
     "shell.execute_reply": "2024-10-30T06:41:29.112255Z",
     "shell.execute_reply.started": "2024-10-30T06:41:29.091503Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# NULL check\n",
    "print(merged_df.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T06:41:59.531094Z",
     "iopub.status.busy": "2024-10-30T06:41:59.530628Z",
     "iopub.status.idle": "2024-10-30T06:41:59.583306Z",
     "shell.execute_reply": "2024-10-30T06:41:59.582214Z",
     "shell.execute_reply.started": "2024-10-30T06:41:59.531053Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "merged_df = merged_df.dropna(how = 'any') # drop rows with null values\n",
    "print(merged_df.isnull().values.any()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T06:42:08.189231Z",
     "iopub.status.busy": "2024-10-30T06:42:08.188811Z",
     "iopub.status.idle": "2024-10-30T06:42:08.194667Z",
     "shell.execute_reply": "2024-10-30T06:42:08.193487Z",
     "shell.execute_reply.started": "2024-10-30T06:42:08.189192Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(len(merged_df)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T06:44:27.013880Z",
     "iopub.status.busy": "2024-10-30T06:44:27.013444Z",
     "iopub.status.idle": "2024-10-30T06:44:27.475893Z",
     "shell.execute_reply": "2024-10-30T06:44:27.474817Z",
     "shell.execute_reply.started": "2024-10-30T06:44:27.013843Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# remove all characters other than Hangeul\n",
    "merged_df['text'] = merged_df['text'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# SKIP END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T06:27:24.910169Z",
     "iopub.status.busy": "2025-05-01T06:27:24.909704Z",
     "iopub.status.idle": "2025-05-01T06:27:37.390781Z",
     "shell.execute_reply": "2025-05-01T06:27:37.389523Z",
     "shell.execute_reply.started": "2025-05-01T06:27:24.910127Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install konlpy\n",
    "\n",
    "# from konlpy.tag import Okt\n",
    "# okt = Okt()\n",
    "\n",
    "# !pip install fugashi[unidic-lite]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T06:27:42.363864Z",
     "iopub.status.busy": "2025-05-01T06:27:42.362914Z",
     "iopub.status.idle": "2025-05-01T06:27:43.517369Z",
     "shell.execute_reply": "2025-05-01T06:27:43.516248Z",
     "shell.execute_reply.started": "2025-05-01T06:27:42.363814Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import fugashi\n",
    "\n",
    "tagger = fugashi.Tagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T06:27:51.980291Z",
     "iopub.status.busy": "2025-05-01T06:27:51.979542Z",
     "iopub.status.idle": "2025-05-01T06:27:52.015059Z",
     "shell.execute_reply": "2025-05-01T06:27:52.013859Z",
     "shell.execute_reply.started": "2025-05-01T06:27:51.980246Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# NULL check\n",
    "print(comments.isnull().values.any()) # => True\n",
    "\n",
    "comments = comments.dropna(how = 'any') # drop rows with null values\n",
    "\n",
    "print(comments.isnull().values.any()) # => False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T06:28:18.481637Z",
     "iopub.status.busy": "2025-05-01T06:28:18.481225Z",
     "iopub.status.idle": "2025-05-01T06:30:04.798230Z",
     "shell.execute_reply": "2025-05-01T06:30:04.797134Z",
     "shell.execute_reply.started": "2025-05-01T06:28:18.481599Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43589/43589 [00:00<00:00, 60743.21it/s]\n"
     ]
    }
   ],
   "source": [
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "tokenized_data = []\n",
    "\n",
    "# merged_df['text'] => comments['Comment']\n",
    "for sentence in tqdm.tqdm(comments['Comment']): \n",
    "    sentence = str(sentence).strip()\n",
    "    \n",
    "    if not sentence:  # 빈 문자열이면 건너뛰기\n",
    "        continue\n",
    "        \n",
    "    tokenized_sentence = [word.surface for word in tagger(sentence)]\n",
    "    \n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence \n",
    "                                  if not word in stopwords # 조건1\n",
    "                                     and len(word) >= 2 # 조건2   \n",
    "                                     and word.isalpha()]  # 한글이나 영어 \n",
    "    \n",
    "    if stopwords_removed_sentence:  # 빈 리스트가 아니라면 추가\n",
    "        tokenized_data.append(stopwords_removed_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T01:36:11.732647Z",
     "iopub.status.busy": "2025-04-14T01:36:11.732002Z",
     "iopub.status.idle": "2025-04-14T01:36:30.549604Z",
     "shell.execute_reply": "2025-04-14T01:36:30.548186Z",
     "shell.execute_reply.started": "2025-04-14T01:36:11.732609Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp311-cp311-win_amd64.whl.metadata (8.2 kB)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Downloading scipy-1.13.1-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in d:\\apps\\minicond3\\envs\\python-env-311\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "Downloading gensim-4.3.3-cp311-cp311-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.4/24.0 MB 11.2 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 4.2/24.0 MB 10.9 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 5.2/24.0 MB 8.8 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 6.6/24.0 MB 7.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 7.6/24.0 MB 7.3 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 8.9/24.0 MB 7.1 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 10.2/24.0 MB 7.0 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 11.0/24.0 MB 6.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 11.5/24.0 MB 6.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 12.6/24.0 MB 5.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 13.4/24.0 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 14.4/24.0 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 15.2/24.0 MB 5.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.0/24.0 MB 5.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.0/24.0 MB 5.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.8/24.0 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.1/24.0 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.0/24.0 MB 5.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.3/24.0 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.9/24.0 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 5.7 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 2.1/15.8 MB 11.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 3.1/15.8 MB 7.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.5/15.8 MB 7.7 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.2/15.8 MB 6.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 6.3/15.8 MB 5.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 7.1/15.8 MB 5.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 8.1/15.8 MB 5.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 9.2/15.8 MB 5.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 10.5/15.8 MB 5.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.8/15.8 MB 5.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.1/15.8 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.7/15.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 5.8 MB/s eta 0:00:00\n",
      "Downloading scipy-1.13.1-cp311-cp311-win_amd64.whl (46.2 MB)\n",
      "   ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.6/46.2 MB 8.3 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 3.4/46.2 MB 8.7 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 5.8/46.2 MB 9.5 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 8.4/46.2 MB 10.0 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 10.7/46.2 MB 10.5 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 13.4/46.2 MB 10.6 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 15.7/46.2 MB 10.8 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 18.1/46.2 MB 10.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 20.7/46.2 MB 11.0 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 22.5/46.2 MB 10.8 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 24.6/46.2 MB 10.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 26.7/46.2 MB 10.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 29.1/46.2 MB 10.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 31.5/46.2 MB 10.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 33.6/46.2 MB 10.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 35.1/46.2 MB 10.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 37.0/46.2 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 39.3/46.2 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.7/46.2 MB 10.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.0/46.2 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.6/46.2 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.1/46.2 MB 10.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.1/46.2 MB 10.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.1/46.2 MB 10.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.1/46.2 MB 10.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 46.2/46.2 MB 8.6 MB/s eta 0:00:00\n",
      "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: smart-open, numpy, scipy, gensim\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.15.2\n",
      "    Uninstalling scipy-1.15.2:\n",
      "      Successfully uninstalled scipy-1.15.2\n",
      "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\apps\\minicond3\\envs\\python-env-311\\Lib\\site-packages\\~-mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\apps\\minicond3\\envs\\python-env-311\\Lib\\site-packages\\~-mpy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\apps\\minicond3\\envs\\python-env-311\\Lib\\site-packages\\~cipy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\apps\\minicond3\\envs\\python-env-311\\Lib\\site-packages\\~cipy'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T01:36:34.143758Z",
     "iopub.status.busy": "2025-04-14T01:36:34.143349Z",
     "iopub.status.idle": "2025-04-14T01:36:43.874842Z",
     "shell.execute_reply": "2025-04-14T01:36:43.873814Z",
     "shell.execute_reply.started": "2025-04-14T01:36:34.143719Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(sentences = tokenized_data, vector_size = 100, window = 5, min_count = 5, workers = 4, sg = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T01:36:48.378751Z",
     "iopub.status.busy": "2025-04-14T01:36:48.378168Z",
     "iopub.status.idle": "2025-04-14T01:36:48.385880Z",
     "shell.execute_reply": "2025-04-14T01:36:48.384658Z",
     "shell.execute_reply.started": "2025-04-14T01:36:48.378713Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9225, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T03:13:22.199443Z",
     "iopub.status.busy": "2025-01-22T03:13:22.199002Z",
     "iopub.status.idle": "2025-01-22T03:13:22.210239Z",
     "shell.execute_reply": "2025-01-22T03:13:22.208977Z",
     "shell.execute_reply.started": "2025-01-22T03:13:22.199404Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('셰프', 0.9992114305496216), ('이게', 0.9991965293884277), ('ㅋㅋㅋ', 0.999139130115509), ('진짜', 0.9991201162338257), ('근데', 0.9991068840026855), ('쉐프', 0.9990993142127991), ('ㅈㄴ', 0.9990933537483215), ('아니', 0.9990734457969666), ('ㅋㅋ', 0.9990469813346863), ('그냥', 0.9989633560180664)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(\"백종원\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T03:13:25.221689Z",
     "iopub.status.busy": "2025-01-22T03:13:25.221265Z",
     "iopub.status.idle": "2025-01-22T03:13:25.231754Z",
     "shell.execute_reply": "2025-01-22T03:13:25.229237Z",
     "shell.execute_reply.started": "2025-01-22T03:13:25.221652Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('안성재', 0.9994552731513977), ('에드워드', 0.9988729953765869), ('최강록', 0.9987758994102478), ('백종원', 0.9987531304359436), ('셰프', 0.9987066984176636), ('셰프님', 0.9986703991889954), ('쉐프', 0.9985906481742859), ('진짜', 0.9984706044197083), ('귀여워', 0.9982514977455139), ('너무', 0.9982216358184814)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(\"최현석\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save W2V model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T01:37:05.648422Z",
     "iopub.status.busy": "2025-04-14T01:37:05.648016Z",
     "iopub.status.idle": "2025-04-14T01:37:06.115316Z",
     "shell.execute_reply": "2025-04-14T01:37:06.114497Z",
     "shell.execute_reply.started": "2025-04-14T01:37:05.648387Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('ko_w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T01:37:09.952234Z",
     "iopub.status.busy": "2025-04-14T01:37:09.951252Z",
     "iopub.status.idle": "2025-04-14T01:37:17.346938Z",
     "shell.execute_reply": "2025-04-14T01:37:17.345653Z",
     "shell.execute_reply.started": "2025-04-14T01:37:09.952191Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 14:36:00,846 - word2vec2tensor - INFO - running d:\\apps\\minicond3\\envs\\python-env-311\\Lib\\site-packages\\gensim\\scripts\\word2vec2tensor.py --input ko_w2v --output ko_w2v\n",
      "2025-05-02 14:36:00,846 - keyedvectors - INFO - loading projection weights from ko_w2v\n",
      "2025-05-02 14:36:01,507 - utils - INFO - KeyedVectors lifecycle event {'msg': 'loaded (9225, 100) matrix of type float32 from ko_w2v', 'binary': False, 'encoding': 'utf8', 'datetime': '2025-05-02T14:36:01.483753', 'gensim': '4.3.3', 'python': '3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'}\n",
      "2025-05-02 14:36:02,057 - word2vec2tensor - INFO - 2D tensor file saved to ko_w2v_tensor.tsv\n",
      "2025-05-02 14:36:02,057 - word2vec2tensor - INFO - Tensor metadata file saved to ko_w2v_metadata.tsv\n",
      "2025-05-02 14:36:02,058 - word2vec2tensor - INFO - finished running word2vec2tensor.py\n"
     ]
    }
   ],
   "source": [
    "!python -m gensim.scripts.word2vec2tensor --input ko_w2v --output ko_w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization for embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Go to https://projector.tensorflow.org/\n",
    "## and load ko_w2v_tensor.tsv and ko_w2v_metadata.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "python-env-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
